{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models, optimizers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n\n# Define the basic residual block for ResNet-18\ndef residual_block(x, filters, stride=1):\n    shortcut = x\n    x = layers.Conv2D(filters, kernel_size=3, strides=stride, padding='same', use_bias=False)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.ReLU()(x)\n    x = layers.Conv2D(filters, kernel_size=3, strides=1, padding='same', use_bias=False)(x)\n    x = layers.BatchNormalization()(x)\n\n    # Shortcut connection\n    if stride != 1 or shortcut.shape[-1] != filters:\n        shortcut = layers.Conv2D(filters, kernel_size=1, strides=stride, padding='same', use_bias=False)(shortcut)\n        shortcut = layers.BatchNormalization()(shortcut)\n\n    x = layers.Add()([x, shortcut])\n    x = layers.ReLU()(x)\n    return x\n\n# Build ResNet-18 model\ndef build_resnet18(input_shape=(224,224,3), num_classes=10):\n    inputs = layers.Input(shape=input_shape)\n    x = layers.Conv2D(64, kernel_size=7, strides=2, padding='same', use_bias=False)(inputs)\n    x = layers.BatchNormalization()(x)\n    x = layers.ReLU()(x)\n    x = layers.MaxPooling2D(pool_size=3, strides=2, padding='same')(x)\n\n    # 2 blocks of 64 filters\n    x = residual_block(x, 64, stride=1)\n    x = residual_block(x, 64, stride=1)\n\n    # 2 blocks of 128 filters\n    x = residual_block(x, 128, stride=2)\n    x = residual_block(x, 128, stride=1)\n\n    # 2 blocks of 256 filters\n    x = residual_block(x, 256, stride=2)\n    x = residual_block(x, 256, stride=1)\n\n    # 2 blocks of 512 filters\n    x = residual_block(x, 512, stride=2)\n    x = residual_block(x, 512, stride=1)\n\n    x = layers.GlobalAveragePooling2D()(x)\n    x = layers.Dropout(0.3)(x)\n    outputs = layers.Dense(num_classes, activation='softmax')(x)\n\n    model = models.Model(inputs, outputs)\n    return model\n\n# Paths\ntrain_dir = \"/kaggle/input/patho1/kvasirv2/Train1\"\nval_dir = \"/kaggle/input/patho1/kvasirv2/Validation1\"\n\n# Data generators with augmentation for train, only rescaling for val\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\nval_datagen = ImageDataGenerator(rescale=1./255)\n\nbatch_size = 32\nimg_size = (224, 224)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=img_size,\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=True\n)\n\nval_generator = val_datagen.flow_from_directory(\n    val_dir,\n    target_size=img_size,\n    batch_size=batch_size,\n    class_mode='categorical',\n    shuffle=False\n)\n\nnum_classes = len(train_generator.class_indices)\nprint(f\"Number of classes detected: {num_classes}\")\n\n# Build model\nmodel = build_resnet18(input_shape=(224,224,3), num_classes=num_classes)\n\n# Compile\nmodel.compile(optimizer=optimizers.Adam(learning_rate=1e-4),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Callbacks\nearly_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, verbose=1)\ncheckpoint = ModelCheckpoint('resnet18_best.keras', monitor='val_accuracy', save_best_only=True, verbose=1)\n\n# Train\nhistory = model.fit(\n    train_generator,\n    epochs=20,\n    validation_data=val_generator,\n    callbacks=[early_stop, reduce_lr, checkpoint]\n)\n\n# Model is saved automatically by ModelCheckpoint as 'resnet18_best.keras'\n# You can also save manually after training if needed:\n# model.save('resnet18_final.keras')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}