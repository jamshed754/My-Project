Project Title: A Novel Explainable Deep Ensemble Framework for Gastrointestinal Cancer Diagnosis

•	Description – An overview of the code/dataset
This repository provides the complete implementation of a deep learning–based framework for multi-class stomach disease classification using endoscopic images. The dataset comprises three gastrointestinal disease categories: Polyps, Esophagitis, and Ulcerative Colitis, collected and organized following a structured training, validation, and testing protocol. 
The codebase covers the entire experimental pipeline, including dataset splitting, preprocessing, data augmentation, model training, ensemble learning, and explainable AI (XAI) analysis. Preprocessing techniques such as image resizing, normalization, contrast enhancement (CLAHE), sharpening, and Gaussian smoothing are applied to improve visual quality and feature representation. Multiple deep learning architectures—InceptionV3, ResNet-18, and MobileNetV2—are trained using transfer learning, and their predictions are combined through a SoftMax-based ensemble strategy to enhance classification performance.
To ensure model transparency and interpretability, SHAP and LIME techniques are implemented to visualize class-specific decision regions. The provided scripts and notebooks are designed for reproducibility and can be executed in Kaggle or local environments with minimal configuration. This repository supports the experimental results reported in the associated research manuscript and enables researchers to reproduce, validate, and extend the proposed methodology.
•	Dataset Information
The dataset used in this study consists of endoscopic images collected for multi-class stomach disease classification. It includes three clinically relevant gastrointestinal conditions: Polyps, Esophagitis, and Ulcerative Colitis. All images are stored in JPEG (.jpg) format. Before model training, the dataset is systematically divided into training (70%), validation (15%), and testing (15%) subsets to ensure unbiased performance evaluation. The dataset is structured in a hierarchical format compatible with deep learning frameworks such as TensorFlow and Keras.
Code Information
This repository contains modular and well-documented Python scripts and notebooks that implement each stage of the proposed stomach disease classification framework. The code is designed to be reproducible, platform-independent, and compatible with Kaggle and local environments. Each script addresses a specific component of the experimental pipeline, ensuring clarity, reusability, and ease of modification. 
The provided codebase is organized into modular scripts covering all major stages of the experimental pipeline. A dedicated data-splitting script is used to divide the original dataset into training (70%), validation (15%), and testing (15%) subsets while preserving class-wise distribution, and the resulting output follows a standardized directory structure compatible with Keras data generators. Basic preprocessing scripts perform image resizing to 224 × 224 pixels, along with normalization and standardization, ensuring uniform input representations across all subsets. Image enhancement techniques are implemented to improve visual quality and feature discriminability, including Contrast Limited Adaptive Histogram Equalization (CLAHE), image sharpening, and Gaussian blurring; the enhanced images are saved with descriptive filename suffixes to maintain traceability. Data augmentation is applied using geometric transformations such as horizontal and vertical flipping and rotation to expand the dataset and improve model generalization, resulting in approximately 4,500 images per class. Model training scripts are provided for multiple deep learning architectures, including InceptionV3, ResNet-18, and MobileNetV2, where transfer learning is employed by freezing pre-trained backbone layers and training task-specific classification heads. An ensemble learning module combines predictions from individual models using a SoftMax probability averaging strategy, enhancing robustness and overall classification performance. To improve interpretability and clinical trust, separate Explainable AI (XAI) implementations are included for SHAP and LIME, enabling visualization of class-discriminative regions influencing model predictions.  Usage Instruction
Usage Instructions
To reproduce the experiments, users should first organize the endoscopic image dataset into class-wise folders corresponding to Polyps, Esophagitis, and Ulcerative Colitis, ensuring that all images are in standard image formats (e.g., JPG or PNG). The dataset is then split into training, validation, and testing subsets using the provided data-splitting script, which automatically generates a directory structure compatible with TensorFlow and Keras. Basic preprocessing is applied next, including resizing all images to 224 × 224 pixels and normalizing pixel intensities, ensuring consistency across all subsets. Subsequently, image enhancement techniques such as Contrast Limited Adaptive Histogram Equalization (CLAHE), image sharpening, and Gaussian smoothing are applied to improve visual quality and feature representation. Data augmentation is then performed using geometric transformations, including horizontal and vertical flipping and rotation to balance the dataset, resulting in approximately 4,500 images per class. Individual deep learning models—InceptionV3, ResNet-18, and MobileNetV2—are trained using transfer learning, and the trained models are saved in Keras format. The predictions from these models are combined using a SoftMax probability averaging ensemble strategy to obtain final classification results. Finally, Explainable AI techniques, including SHAP and LIME, are applied to generate visual explanations that highlight class-specific regions influencing the model’s decisions. All scripts are compatible with Kaggle and local Python environments, and paths can be adjusted as needed to facilitate reproducibility.
Requirements
The implementation requires Python 3.x along with several widely used scientific and deep learning libraries. The core framework used for model development and training is TensorFlow with the Keras API. NumPy is utilized for numerical computations, while OpenCV is employed for image preprocessing and enhancement operations. Matplotlib is used for the visualization of images, training curves, and explainability outputs. Scikit-learn is incorporated for data splitting, performance evaluation, and utility functions. For model interpretability, SHAP and LIME libraries are required to generate explainable AI visualizations. All dependencies are compatible with Kaggle and standard GPU-enabled environments, and installing the specified libraries ensures full reproducibility of the experimental results.
Methodology
The proposed methodology follows a systematic pipeline for stomach disease image classification, starting from data preparation to model interpretation. Initially, the dataset is divided into training (70%), validation (15%), and testing (15%) subsets while preserving class-wise distribution to avoid data imbalance. Basic preprocessing is then applied, including image resizing to 224 × 224 pixels, normalization, and standardization to ensure input consistency across all deep learning models. To further enhance image quality, contrast enhancement and noise reduction techniques such as Contrast Limited Adaptive Histogram Equalization (CLAHE), image sharpening, and Gaussian blurring are employed.
Subsequently, data augmentation techniques, including horizontal and vertical flipping and rotation, are applied to expand the dataset size to approximately 4,500 images per class, thereby improving model generalization and reducing overfitting. Multiple deep learning architectures—namely InceptionV3, ResNet-18, and MobileNetV2—are trained using transfer learning, where pre-trained backbone layers are frozen, and custom classification heads are fine-tuned on the augmented dataset. Finally, an ensemble learning strategy based on SoftMax probability averaging is utilized to combine predictions from individual models, enhancing robustness and overall classification performance. To improve transparency and clinical reliability, explainable AI techniques such as SHAP and LIME are applied to visualize model decision regions and interpret the classification outcomes.

Citations
If this dataset and accompanying code are used for academic or research purposes, users are encouraged to cite the original dataset sources and the relevant research articles associated with the employed methodologies. Proper citation ensures reproducibility, acknowledges prior work, and supports the transparency of experimental results.
The dataset and code provided in this repository were utilized for experimental validation in the associated research study. References to the dataset source, deep learning architectures, and explainable AI techniques (e.g., SHAP and LIME) should be included as per standard academic practice.
License & Contribution Guidelines
This repository is intended for academic and research purposes. The source code is provided under an open-source license, allowing users to use, modify, and distribute the code for non-commercial research and educational use, provided that proper credit is given to the original authors. If this repository is used in published research, appropriate citation of the related work and dataset sources is expected.
Contributions to this repository are welcome. Researchers and developers may contribute by reporting issues, suggesting improvements, or submitting pull requests. All contributions should follow standard coding practices, include clear documentation, and maintain consistency with the existing project structure. By contributing, users agree that their contributions will be shared under the same license as the original code.






✅ 


